diff --git a/frameworks/av/include/media/stagefright/ColorConverter.h b/frameworks/av/include/media/stagefright/ColorConverter.h
index 270c80966..2edb0dd75 100644
--- a/frameworks/av/include/media/stagefright/ColorConverter.h
+++ b/frameworks/av/include/media/stagefright/ColorConverter.h
@@ -67,6 +67,9 @@ private:
     status_t convertCbYCrY(
             const BitmapParams &src, const BitmapParams &dst);
 
+    status_t convertYCbYCr(
+            const BitmapParams &src, const BitmapParams &dst);
+
     status_t convertYUV420Planar(
             const BitmapParams &src, const BitmapParams &dst);
 
diff --git a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
index a11494d63..102dd9f83 100644
--- a/frameworks/av/media/libstagefright/ACodec.cpp
+++ b/frameworks/av/media/libstagefright/ACodec.cpp
@@ -821,11 +821,7 @@ status_t ACodec::allocateBuffersOnPort(OMX_U32 portIndex) {
 
     status_t err;
     if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
-        if (storingMetadataInDecodedBuffers()) {
-            err = allocateOutputMetadataBuffers();
-        } else {
             err = allocateOutputBuffersFromNativeWindow();
-        }
     } else {
         OMX_PARAM_PORTDEFINITIONTYPE def;
         InitOMXParams(&def);
@@ -1035,6 +1031,25 @@ status_t ACodec::setupNativeWindowSizeFormatAndUsage(
     OMX_COLOR_FORMATTYPE eNativeColorFormat = def.format.video.eColorFormat;
     setNativeWindowColorFormat(eNativeColorFormat);
 #endif
+    ALOGE("ACodec:PATCH:setupNativeWindowSizeFormatAndUsage[%s] def.format.video.eColorFormat(%i)", mComponentName.c_str(), def.format.video.eColorFormat);
+    OMX_COLOR_FORMATTYPE HalColorFormat;
+    status_t omxresuilts;
+    switch (def.format.video.eColorFormat) {
+        case OMX_COLOR_FormatYCbYCr:
+            def.format.video.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            omxresuilts = mOMX->setParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
+            if (omxresuilts != OK) {
+                ALOGE("PATCH:ACodec:configureOutputBuffersFromNativeWindow setParameter(OMX_IndexParamPortDefinition) ERROR");
+            }
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        case OMX_COLOR_FormatYUV420Planar:
+            HalColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        break;
+        default:
+            HalColorFormat = def.format.video.eColorFormat;
+        break;
+    }
 
     ALOGV("gralloc usage: %#x(OMX) => %#x(ACodec)", omxUsage, usage);
     err = setNativeWindowSizeFormatAndUsage(
@@ -1044,7 +1059,7 @@ status_t ACodec::setupNativeWindowSizeFormatAndUsage(
 #ifdef USE_SAMSUNG_COLORFORMAT
             eNativeColorFormat,
 #else
-            def.format.video.eColorFormat,
+            HalColorFormat,
 #endif
             mRotationDegrees,
             usage,
@@ -1885,14 +1900,12 @@ status_t ACodec::configureCodec(
         }
 #endif
 
-        uint32_t usageBits;
-        if (mOMX->getParameter(
-                mNode, (OMX_INDEXTYPE)OMX_IndexParamConsumerUsageBits,
-                &usageBits, sizeof(usageBits)) == OK) {
-            inputFormat->setInt32(
-                    "using-sw-read-often", !!(usageBits & GRALLOC_USAGE_SW_READ_OFTEN));
-        }
     }
+#ifdef HAWAII_HWC
+    else if (!strncmp(mComponentName.c_str(), "OMX.brcm.video.h264.hw.decoder", 30)) {
+           setMinBufferSize(kPortIndexInput, (1280 * 720 * 3) / 2);
+    }
+#endif
 
     int32_t prependSPSPPS = 0;
     if (encoder
@@ -2393,22 +2406,10 @@ status_t ACodec::configureCodec(
         err = setMinBufferSize(kPortIndexInput, (size_t)maxInputSize);
     } else if (!strcmp("OMX.Nvidia.aac.decoder", mComponentName.c_str())) {
         err = setMinBufferSize(kPortIndexInput, 8192);  // XXX
+    } else if (!strncmp(mComponentName.c_str(), "OMX.brcm.video.h264.hw.decoder", 30)) {
+        setMinBufferSize(kPortIndexInput, (1280 * 720 * 3) / 2);
     }
 
-    int32_t priority;
-    if (msg->findInt32("priority", &priority)) {
-        err = setPriority(priority);
-    }
-
-    int32_t rateInt = -1;
-    float rateFloat = -1;
-    if (!msg->findFloat("operating-rate", &rateFloat)) {
-        msg->findInt32("operating-rate", &rateInt);
-        rateFloat = (float)rateInt;  // 16MHz (FLINTMAX) is OK for upper bound.
-    }
-    if (rateFloat > 0) {
-        err = setOperatingRate(rateFloat, video);
-    }
 
     // NOTE: both mBaseOutputFormat and mOutputFormat are outputFormat to signal first frame.
     mBaseOutputFormat = outputFormat;
@@ -3202,12 +3203,37 @@ status_t ACodec::setVideoPortFormatType(
     format.nIndex = 0;
     bool found = false;
 
+    if(format.eColorFormat == OMX_COLOR_FormatYCbYCr){
+        if (!strncmp(mComponentName.c_str(), "OMX.brcm.", 9)){
+            format.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+            status_t errs = mOMX->setParameter(mNode, OMX_IndexParamVideoPortFormat, &format, sizeof(format));
+                if (errs != OK){
+                    ALOGE("PATCH:ACodec:setVideoPortFormatType setParameter failed: %d", errs);
+                }
+        }
+    }
+    if(colorFormat == OMX_COLOR_FormatYCbYCr){
+        if (!strncmp(mComponentName.c_str(), "OMX.brcm.", 9)){
+            colorFormat = OMX_COLOR_FormatYUV420Planar;
+        }
+    }
+
     for (OMX_U32 index = 0; index <= kMaxIndicesToCheck; ++index) {
         format.nIndex = index;
         status_t err = mOMX->getParameter(
                 mNode, OMX_IndexParamVideoPortFormat,
                 &format, sizeof(format));
 
+        if (!strncmp("OMX.brcm.video.h264.hw.decoder", mComponentName.c_str(), 30)) {
+            format.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+        }
+        err = mOMX->getParameter(
+                mNode, OMX_IndexParamVideoPortFormat,
+                     &format, sizeof(format));
+        if((unsigned int)err == 0x80001005){
+            err= OMX_ErrorNoMore;
+        }
+
         if (err != OK) {
             return err;
         }
@@ -3316,6 +3342,21 @@ status_t ACodec::setSupportedOutputFormat(bool getLegacyFlexibleFormat) {
                 || format.eColorFormat == OMX_TI_COLOR_FormatYUV420PackedSemiPlanar) {
             break;
         }
+        if (!strncmp("OMX.brcm.video.h264.hw.decoder", mComponentName.c_str(), 30)) {
+            format.eColorFormat = OMX_COLOR_FormatYUV420Planar;
+        }
+        if (format.eColorFormat == OMX_COLOR_FormatYUV420Planar) {
+            while (OMX_ErrorNoMore != err) {
+            format.nIndex++;
+            err = mOMX->getParameter(
+                    mNode, OMX_IndexParamVideoPortFormat,
+                        &format, sizeof(format));
+            if((unsigned int)err == 0x80001005){
+                err = OMX_ErrorNoMore;
+            }
+            }
+        }
+
         // find best legacy non-standard format
         OMX_U32 flexibleEquivalent;
         if (legacyFormat.eColorFormat == OMX_COLOR_FormatUnused
@@ -4892,6 +4933,16 @@ bool ACodec::describeDefaultColorFormat(DescribeColorFormat2Params &params) {
     image.mNumPlanes = 0;
 
     const OMX_COLOR_FORMATTYPE fmt = params.eColorFormat;
+
+    switch(params.eColorFormat){
+        case OMX_COLOR_FormatYCbYCr:{
+            params.eColorFormat = (OMX_COLOR_FORMATTYPE)HAL_PIXEL_FORMAT_YV12;
+        }
+        break;
+        default:
+        break;
+    }
+
     image.mWidth = params.nFrameWidth;
     image.mHeight = params.nFrameHeight;
 
@@ -7822,14 +7873,6 @@ status_t ACodec::setParameters(const sp<AMessage> &params) {
         }
     }
 
-    float rate;
-    if (params->findFloat("operating-rate", &rate) && rate > 0) {
-        status_t err = setOperatingRate(rate, mIsVideo);
-        if (err != OK) {
-            ALOGE("Failed to set parameter 'operating-rate' (err %d)", err);
-            return err;
-        }
-    }
 
     int32_t intraRefreshPeriod = 0;
     if (params->findInt32("intra-refresh-period", &intraRefreshPeriod)
@@ -8494,9 +8537,13 @@ status_t ACodec::queryCapabilities(
                     builder->addColorFormat(flexibleEquivalent);
                 }
             }
-            supportedColors.push(portFormat.eColorFormat);
-            builder->addColorFormat(portFormat.eColorFormat);
-
+            if(portFormat.eColorFormat == OMX_COLOR_FormatYCbYCr) {
+                supportedColors.push(OMX_COLOR_FormatYUV420Planar);
+                builder->addColorFormat(OMX_COLOR_FormatYUV420Planar);
+            }else{
+                supportedColors.push(portFormat.eColorFormat);
+                builder->addColorFormat(portFormat.eColorFormat);
+            }
             if (index == kMaxIndicesToCheck) {
                 ALOGW("[%s] stopping checking formats after %u: %s(%x)",
                         name.c_str(), index,
diff --git a/frameworks/av/media/libstagefright/Android.mk b/frameworks/av/media/libstagefright/Android.mk
index e708f68ae..f86a3fb73 100644
--- a/frameworks/av/media/libstagefright/Android.mk
+++ b/frameworks/av/media/libstagefright/Android.mk
@@ -202,6 +202,10 @@ LOCAL_C_INCLUDES += \
 	$(TOP)/hardware/samsung/exynos4/include
 endif
 
+ifeq ($(TARGET_BOARD_PLATFORM),hawaii)
+LOCAL_CFLAGS += -DHAWAII_HWC
+endif
+
 LOCAL_MODULE:= libstagefright
 
 LOCAL_MODULE_TAGS := optional
diff --git a/frameworks/av/media/libstagefright/MPEG4Writer.cpp b/frameworks/av/media/libstagefright/MPEG4Writer.cpp
index 3e98c133d..20d999e06 100644
--- a/frameworks/av/media/libstagefright/MPEG4Writer.cpp
+++ b/frameworks/av/media/libstagefright/MPEG4Writer.cpp
@@ -2538,18 +2538,10 @@ status_t MPEG4Writer::Track::threadEntry() {
         if (mResumed) {
             int64_t durExcludingEarlierPausesUs = timestampUs - previousPausedDurationUs;
             if (WARN_UNLESS(durExcludingEarlierPausesUs >= 0ll, "for %s track", trackName)) {
-                copy->release();
-                mSource->stop();
-                mIsMalformed = true;
-                break;
             }
 
             int64_t pausedDurationUs = durExcludingEarlierPausesUs - mTrackDurationUs;
             if (WARN_UNLESS(pausedDurationUs >= lastDurationUs, "for %s track", trackName)) {
-                copy->release();
-                mSource->stop();
-                mIsMalformed = true;
-                break;
             }
 
             previousPausedDurationUs += pausedDurationUs - lastDurationUs;
@@ -2558,10 +2550,6 @@ status_t MPEG4Writer::Track::threadEntry() {
 
         timestampUs -= previousPausedDurationUs;
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            mSource->stop();
-            mIsMalformed = true;
-            break;
         }
 
         if (!mIsAudio) {
@@ -2590,10 +2578,6 @@ status_t MPEG4Writer::Track::threadEntry() {
                 cttsOffsetTimeUs = 0;
             }
             if (WARN_UNLESS(cttsOffsetTimeUs >= 0ll, "for %s track", trackName)) {
-                copy->release();
-                mSource->stop();
-                mIsMalformed = true;
-                break;
             }
 
             timestampUs = decodingTimeUs;
@@ -2604,10 +2588,6 @@ status_t MPEG4Writer::Track::threadEntry() {
             currCttsOffsetTimeTicks =
                     (cttsOffsetTimeUs * mTimeScale + 500000LL) / 1000000LL;
             if (WARN_UNLESS(currCttsOffsetTimeTicks <= 0x0FFFFFFFFLL, "for %s track", trackName)) {
-                copy->release();
-                mSource->stop();
-                mIsMalformed = true;
-                break;
             }
 
             if (mStszTableEntries->count() == 0) {
@@ -2648,10 +2628,6 @@ status_t MPEG4Writer::Track::threadEntry() {
         }
 
         if (WARN_UNLESS(timestampUs >= 0ll, "for %s track", trackName)) {
-            copy->release();
-            mSource->stop();
-            mIsMalformed = true;
-            break;
         }
 
         ALOGV("%s media time stamp: %" PRId64 " and previous paused duration %" PRId64,
@@ -2671,10 +2647,6 @@ status_t MPEG4Writer::Track::threadEntry() {
         if (currDurationTicks < 0ll) {
             ALOGE("do not support out of order frames (timestamp: %lld < last: %lld for %s track",
                     (long long)timestampUs, (long long)lastTimestampUs, trackName);
-            copy->release();
-            mSource->stop();
-            mIsMalformed = true;
-            break;
         }
 
         // if the duration is different for this sample, see if it is close enough to the previous
@@ -2772,7 +2744,6 @@ status_t MPEG4Writer::Track::threadEntry() {
     }
 
     if (isTrackMalFormed()) {
-        err = ERROR_MALFORMED;
     }
 
     mOwner->trackProgressStatus(mTrackId, -1, err);
diff --git a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
index 3ca7cc05c..21bfb179c 100644
--- a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
+++ b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
@@ -48,6 +48,7 @@ bool ColorConverter::isValid() const {
     switch (mSrcFormat) {
         case OMX_COLOR_FormatYUV420Planar:
         case OMX_COLOR_FormatCbYCrY:
+        case OMX_COLOR_FormatYCbYCr:
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
@@ -117,6 +118,10 @@ status_t ColorConverter::convert(
         case OMX_COLOR_FormatCbYCrY:
             err = convertCbYCrY(src, dst);
             break;
+            
+        case OMX_COLOR_FormatYCbYCr:
+            err = convertYCbYCr(src, dst);
+            break;     
 
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
             err = convertQCOMYUV420SemiPlanar(src, dst);
@@ -204,6 +209,71 @@ status_t ColorConverter::convertCbYCrY(
     return OK;
 }
 
+status_t ColorConverter::convertYCbYCr(
+        const BitmapParams &src, const BitmapParams &dst) {
+        ALOGE("PATCH:ColorConverter:convertYCbYCr");
+    // XXX Untested
+
+    uint8_t *kAdjustedClip = initClip();
+
+    if (!((src.mCropLeft & 1) == 0
+        && src.cropWidth() == dst.cropWidth()
+        && src.cropHeight() == dst.cropHeight())) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    uint16_t *dst_ptr = (uint16_t *)dst.mBits
+        + dst.mCropTop * dst.mWidth + dst.mCropLeft;
+
+    const uint8_t *src_ptr = (const uint8_t *)src.mBits
+        + (src.mCropTop * dst.mWidth + src.mCropLeft) * 2;
+
+    for (size_t y = 0; y < src.cropHeight(); ++y) {
+        for (size_t x = 0; x < src.cropWidth(); x += 2) {
+            signed y1 = (signed)src_ptr[2 * x ] - 16;
+            signed y2 = (signed)src_ptr[2 * x + 2] - 16;
+            signed u = (signed)src_ptr[2 * x + 1] - 128;  
+            signed v = (signed)src_ptr[2 * x + 3] - 128;
+
+            signed u_b = u * 517;
+            signed u_g = -u * 100;
+            signed v_g = -v * 208;
+            signed v_r = v * 409;
+
+            signed tmp1 = y1 * 298;
+            signed b1 = (tmp1 + u_b) / 256;
+            signed g1 = (tmp1 + v_g + u_g) / 256;
+            signed r1 = (tmp1 + v_r) / 256;
+
+            signed tmp2 = y2 * 298;
+            signed b2 = (tmp2 + u_b) / 256;
+            signed g2 = (tmp2 + v_g + u_g) / 256;
+            signed r2 = (tmp2 + v_r) / 256;
+
+            uint32_t rgb1 =
+                ((kAdjustedClip[r1] >> 3) << 11)
+                | ((kAdjustedClip[g1] >> 2) << 5)
+                | (kAdjustedClip[b1] >> 3);
+
+            uint32_t rgb2 =
+                ((kAdjustedClip[r2] >> 3) << 11)
+                | ((kAdjustedClip[g2] >> 2) << 5)
+                | (kAdjustedClip[b2] >> 3);
+
+            if (x + 1 < src.cropWidth()) {
+                *(uint32_t *)(&dst_ptr[x]) = (rgb2 << 16) | rgb1;
+            } else {
+                dst_ptr[x] = rgb1;
+            }
+        }
+
+        src_ptr += src.mWidth * 2;
+        dst_ptr += dst.mWidth;
+    }
+
+    return OK;
+}
+
 status_t ColorConverter::convertYUV420PlanarUseLibYUV(
         const BitmapParams &src, const BitmapParams &dst) {
     if (!((src.mCropLeft & 1) == 0
@@ -557,4 +627,4 @@ uint8_t *ColorConverter::initClip() {
     return &mClip[-kClipMin];
 }
 
-}  // namespace android
+}  // namespace android
\ No newline at end of file
diff --git a/frameworks/av/media/libstagefright/omx/GraphicBufferSource.cpp b/frameworks/av/media/libstagefright/omx/GraphicBufferSource.cpp
index 3e5467014..c91e95459 100644
--- a/frameworks/av/media/libstagefright/omx/GraphicBufferSource.cpp
+++ b/frameworks/av/media/libstagefright/omx/GraphicBufferSource.cpp
@@ -382,6 +382,7 @@ void GraphicBufferSource::codecBufferEmptied(OMX_BUFFERHEADERTYPE* header, int f
             }
         } else if (type == kMetadataBufferTypeANWBuffer
                 && header->nAllocLen >= sizeof(VideoNativeMetadata)) {
+#ifndef HAWAII_HWC
             VideoNativeMetadata &nativeMeta = *(VideoNativeMetadata *)data;
             if (nativeMeta.pBuffer != codecBuffer.mGraphicBuffer->getNativeBuffer()) {
                 // should never happen
@@ -389,6 +390,7 @@ void GraphicBufferSource::codecBufferEmptied(OMX_BUFFERHEADERTYPE* header, int f
                         nativeMeta.pBuffer, codecBuffer.mGraphicBuffer->getNativeBuffer());
                 CHECK(!"codecBufferEmptied: mismatched buffer");
             }
+#endif
         }
     }
 
diff --git a/frameworks/av/services/audioflinger/Android.mk b/frameworks/av/services/audioflinger/Android.mk
index 886421516..e5777fc67 100644
--- a/frameworks/av/services/audioflinger/Android.mk
+++ b/frameworks/av/services/audioflinger/Android.mk
@@ -112,6 +112,10 @@ ifeq ($(strip $(DOLBY_ENABLE)),true)
 endif
 # DOLBY_END
 
+ifeq ($(TARGET_BOARD_PLATFORM),hawaii)
+LOCAL_CFLAGS += -DHAWAII_HWC
+endif
+
 include $(BUILD_SHARED_LIBRARY)
 
 #
diff --git a/frameworks/av/services/audioflinger/Threads.cpp b/frameworks/av/services/audioflinger/Threads.cpp
index e8c80c17c..a0ef35993 100644
--- a/frameworks/av/services/audioflinger/Threads.cpp
+++ b/frameworks/av/services/audioflinger/Threads.cpp
@@ -6462,6 +6462,7 @@ reacquire_wakelock:
         mTimestamp.mPosition[ExtendedTimestamp::LOCATION_SERVER] += framesRead;
         mTimestamp.mTimeNs[ExtendedTimestamp::LOCATION_SERVER] = systemTime();
 
+#ifndef HAWAII_HWC
         // Update server timestamp with kernel stats
         if (mInput->stream->get_capture_position != nullptr
                 && mPipeSource.get() == nullptr /* don't obtain for FastCapture, could block */) {
@@ -6477,6 +6478,7 @@ reacquire_wakelock:
                 // as the read obtains a lock, preventing the timestamp call from executing.
             }
         }
+#endif
         // Use this to track timestamp information
         // ALOGD("%s", mTimestamp.toString().c_str());
 
diff --git a/frameworks/native/services/surfaceflinger/Android.mk b/frameworks/native/services/surfaceflinger/Android.mk
index 18cc946be..c64a79133 100644
--- a/frameworks/native/services/surfaceflinger/Android.mk
+++ b/frameworks/native/services/surfaceflinger/Android.mk
@@ -61,6 +61,10 @@ else
     LOCAL_SRC_FILES += \
         SurfaceFlinger_hwc1.cpp \
         DisplayHardware/HWComposer_hwc1.cpp
+
+    ifeq ($(TARGET_BOARD_PLATFORM),hawaii)
+       LOCAL_CFLAGS += -DHAWAII_HWC
+    endif
 endif
 
 ifeq ($(TARGET_BOARD_PLATFORM),omap4)
diff --git a/frameworks/native/services/surfaceflinger/SurfaceFlinger_hwc1.cpp b/frameworks/native/services/surfaceflinger/SurfaceFlinger_hwc1.cpp
index e0b2d55b8..93e65d3f4 100644
--- a/frameworks/native/services/surfaceflinger/SurfaceFlinger_hwc1.cpp
+++ b/frameworks/native/services/surfaceflinger/SurfaceFlinger_hwc1.cpp
@@ -3728,6 +3728,10 @@ status_t SurfaceFlinger::captureScreenImplLocked(
         bool isLocalScreenshot, bool useReadPixels)
 {
     ATRACE_CALL();
+// Rotation artifact problems when useReadPixels is false
+#ifdef HAWAII_HWC
+    useReadPixels = true;
+#endif
 
     // get screen geometry
     uint32_t hw_w = hw->getWidth();
